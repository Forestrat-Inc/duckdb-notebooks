{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bronze Layer Creation\n",
    "\n",
    "This notebook creates the bronze layer by ingesting raw data from S3 into DuckDB tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Bronze Layer Creation Started\n",
      "üîó S3 Ingestion Path: s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.database import DuckDBManager\n",
    "from config.settings import config\n",
    "\n",
    "# Initialize components\n",
    "config.setup_logging()\n",
    "db_manager = DuckDBManager()\n",
    "\n",
    "print(\"üèóÔ∏è Bronze Layer Creation Started\")\n",
    "print(f\"üîó S3 Ingestion Path: {config.INGESTION_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Bronze Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 17:25:48,716 - utils.database - INFO - S3 credentials configured\n",
      "2025-06-18 17:25:48,717 - utils.database - INFO - DuckDB connection configured successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating bronze schema...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db529fdf64445918ef63106297b88fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 17:31:55,161 - utils.database - INFO - SQL statement executed successfully\n",
      "2025-06-18 17:31:55,171 - utils.database - INFO - Query executed successfully. Returned 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bronze schema and tables created successfully\n",
      "üìä Bronze layer contains 100,822,111 rows\n"
     ]
    }
   ],
   "source": [
    "# Create bronze schema and tables\n",
    "print(\"üìä Creating bronze schema...\")\n",
    "\n",
    "bronze_schema_sql = \"\"\"\n",
    "-- Create bronze schema\n",
    "CREATE SCHEMA IF NOT EXISTS bronze;\n",
    "\n",
    "-- Create bronze layer table for bond data\n",
    "CREATE OR REPLACE TABLE bronze.bond_data AS\n",
    "SELECT \n",
    "    *,\n",
    "    filename as source_file,\n",
    "    REGEXP_EXTRACT(filename, '(\\\\\\\\d{4}-\\\\\\\\d{2}-\\\\\\\\d{2})', 1) as data_date,\n",
    "    current_timestamp as ingestion_timestamp\n",
    "FROM read_csv(?, \n",
    "             AUTO_DETECT=true, \n",
    "             FILENAME=true,\n",
    "             UNION_BY_NAME=true)\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Create the bronze table\n",
    "    result = db_manager.execute_sql(\n",
    "        bronze_schema_sql.replace('?', f\"'{config.INGESTION_PATH}/*/*.csv.gz'\")\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Bronze schema and tables created successfully\")\n",
    "    \n",
    "    # Get row count\n",
    "    count_result = db_manager.execute_query(\"SELECT COUNT(*) as row_count FROM bronze.bond_data\")\n",
    "    row_count = count_result['row_count'].iloc[0]\n",
    "    print(f\"üìä Bronze layer contains {row_count:,} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Bronze layer creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing data quality checks...\n",
      "\n",
      "üìä Bronze Layer Quality Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 17:31:55,435 - utils.database - INFO - Query executed successfully. Returned 1 rows\n",
      "2025-06-18 17:31:55,492 - utils.database - INFO - Query executed successfully. Returned 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total Records: {'count': 100822111}\n",
      "  Unique Files: {'count': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 17:31:55,935 - utils.database - INFO - Query executed successfully. Returned 1 rows\n",
      "2025-06-18 17:31:55,940 - utils.database - INFO - Query executed successfully. Returned 1 rows\n",
      "2025-06-18 17:31:55,976 - utils.database - INFO - Query executed successfully. Returned 5 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Date Range: {'min_date': '', 'max_date': ''}\n",
      "  Null Values: {'count': 0}\n",
      "\n",
      "üîç Sample Data:\n",
      "        #RIC        Domain                        Date-Time GMT Offset   Type  \\\n",
      "0  .TRX50GBP  Market Price 2023-09-01 02:59:58.447680-04:00         +1  Trade   \n",
      "1  .TRX50GBP  Market Price 2023-09-01 03:00:58.438312-04:00         +1  Trade   \n",
      "2  .TRX50GBP  Market Price 2023-09-01 03:01:58.408014-04:00         +1  Trade   \n",
      "3  .TRX50GBP  Market Price 2023-09-01 03:02:58.438451-04:00         +1  Trade   \n",
      "4  .TRX50GBP  Market Price 2023-09-01 03:03:58.432486-04:00         +1  Trade   \n",
      "\n",
      "  Ex/Cntrb.ID   LOC   Price  Volume  Market VWAP  ... Implied Yield  Delta  \\\n",
      "0        None  None  113.90    <NA>          NaN  ...          None   None   \n",
      "1        None  None  114.23    <NA>          NaN  ...          None   None   \n",
      "2        None  None  114.20    <NA>          NaN  ...          None   None   \n",
      "3        None  None  114.17    <NA>          NaN  ...          None   None   \n",
      "4        None  None  114.15    <NA>          NaN  ...          None   None   \n",
      "\n",
      "   Gamma   Rho Theta  Vega                                           filename  \\\n",
      "0   None  None  None  None  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...   \n",
      "1   None  None  None  None  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...   \n",
      "2   None  None  None  None  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...   \n",
      "3   None  None  None  None  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...   \n",
      "4   None  None  None  None  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...   \n",
      "\n",
      "                                         source_file data_date  \\\n",
      "0  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...             \n",
      "1  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...             \n",
      "2  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...             \n",
      "3  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...             \n",
      "4  s3://vendor-data-s3/LSEG/TRTH/LSE/ingestion/20...             \n",
      "\n",
      "               ingestion_timestamp  \n",
      "0 2025-06-18 17:25:48.719000-04:00  \n",
      "1 2025-06-18 17:25:48.719000-04:00  \n",
      "2 2025-06-18 17:25:48.719000-04:00  \n",
      "3 2025-06-18 17:25:48.719000-04:00  \n",
      "4 2025-06-18 17:25:48.719000-04:00  \n",
      "\n",
      "[5 rows x 117 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform data quality checks on bronze layer\n",
    "print(\"üîç Performing data quality checks...\")\n",
    "\n",
    "quality_checks = {\n",
    "    \"Total Records\": \"SELECT COUNT(*) as count FROM bronze.bond_data\",\n",
    "    \"Unique Files\": \"SELECT COUNT(DISTINCT source_file) as count FROM bronze.bond_data\",\n",
    "    \"Date Range\": \"SELECT MIN(data_date) as min_date, MAX(data_date) as max_date FROM bronze.bond_data WHERE data_date IS NOT NULL\",\n",
    "    \"Null Values\": \"SELECT COUNT(*) as count FROM bronze.bond_data WHERE data_date IS NULL\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"\\nüìä Bronze Layer Quality Report:\")\n",
    "    for check_name, query in quality_checks.items():\n",
    "        result = db_manager.execute_query(query)\n",
    "        print(f\"  {check_name}: {result.iloc[0].to_dict()}\")\n",
    "    \n",
    "    # Sample data preview\n",
    "    sample_data = db_manager.execute_query(\"SELECT * FROM bronze.bond_data LIMIT 5\")\n",
    "    print(\"\\nüîç Sample Data:\")\n",
    "    print(sample_data)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Quality checks failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Bronze Layer Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 17:31:56,018 - utils.database - INFO - Query executed successfully. Returned 117 rows\n",
      "2025-06-18 17:31:56,036 - utils.database - INFO - Query executed successfully. Returned 1 rows\n",
      "2025-06-18 17:31:56,042 - utils.database - INFO - SQL statement executed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Bronze Layer Summary\n",
      "==============================\n",
      "‚úÖ Table created: bronze.bond_data\n",
      "üìä Columns: 117\n",
      "üóÇÔ∏è  Schema: bronze\n",
      "‚úÖ Process logged to audit table\n",
      "\n",
      "üéâ Bronze layer creation completed successfully!\n",
      "üìå Next: Run 04_silver_layer.ipynb to clean and transform the data\n"
     ]
    }
   ],
   "source": [
    "# Generate bronze layer summary\n",
    "print(\"üìã Bronze Layer Summary\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    # Get table info\n",
    "    table_info = db_manager.execute_query(\"DESCRIBE bronze.bond_data\")\n",
    "    print(f\"‚úÖ Table created: bronze.bond_data\")\n",
    "    print(f\"üìä Columns: {len(table_info)}\")\n",
    "    print(f\"üóÇÔ∏è  Schema: bronze\")\n",
    "    \n",
    "    # Log completion\n",
    "    completion_log = \"\"\"\n",
    "    INSERT INTO audit.data_ingestion_log \n",
    "    (log_id, source_path, record_count, processing_status, error_message)\n",
    "    VALUES (nextval('audit.log_seq'), 'bronze_layer', ?, 'completed', 'Bronze layer created successfully')\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        count_result = db_manager.execute_query(\"SELECT COUNT(*) as count FROM bronze.bond_data\")\n",
    "        record_count = count_result['count'].iloc[0]\n",
    "        db_manager.execute_sql(completion_log.replace('?', str(record_count)))\n",
    "        print(\"‚úÖ Process logged to audit table\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Audit logging skipped (table may not exist)\")\n",
    "    \n",
    "    print(\"\\nüéâ Bronze layer creation completed successfully!\")\n",
    "    print(\"üìå Next: Run 04_silver_layer.ipynb to clean and transform the data\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Summary generation failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
